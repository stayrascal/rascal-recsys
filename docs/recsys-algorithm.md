## 推荐算法

### FM
FM(Factorization Machine)主要是为了解决数据稀疏的情况下，特征怎样组合的问题。
- One-hot编码的缺点：
    - 如果对categorical特征数据使用传统的one-hot编码后，对应的样本数据就会变得很稀疏，数据的稀疏性，是我们在实际应用场景中面临的一个非常常见的挑战与问题。
    - one-hot编码带来的另一个问题是特征空间变大。
- 特征组合：
    - 普通的线性模型，是将各个特征独立考虑的，并没有考虑到特征与特征之间的相互关系。但实际上，大量的特征之间是有关联的。
    - 可以采用多项式模型来表述特征间的相关性，与线性模型相比，FM的模型就多了后面特征组合的部分
    - 其实从表现上来看，就是把每一个特征从一个稀疏的one-hot向量变成一个通过学习而来的稠密的k维的隐向量。

### FFM(Field-aware Factorization Machine)
FFM模型中引入了类别的概念，即field。每一维特征 xi，针对其它特征的每一种field fj，都会学习一个隐向量 v_i,fj。因此，隐向量不仅与特征相关，也与field相关。假设样本的 n个特征属于 f个field，那么FFM的二次项有 nf个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型。
FM模型中，每个特征都有一个自己的隐向量，不同特征之间组合的时候，直接对对应特征向量进行内积，如特征A和特征B、特征C组合时，特征A的向量都是一样的。在FFM的场景中，特征A和特征B、特征C组合时的特征向量不一致。

### DeepFM
FM对于每一维特征的隐变量内积来提取特征组合，理论上来讲FM可以对高阶特征组合进行建模，但实际上因为计算复杂度的原因一般都只用到了二阶特征组合，对于高阶的特征组合来说，可以通过多层的神经网络即DNN去解决。
DeepFM包含两部分：因子分解机部分与神经网络部分，分别负责低阶特征的提取和高阶特征的提取。这两部分共享同样的输入。
- 深度部分是一个前馈神经网络。与图像或者语音这类输入不同，图像语音的输入一般是连续而且密集的，然而用于CTR的输入一般是及其稀疏的。所以需要重新设计网络结构。一般实现方式为在第一层隐含层之前，引入一个嵌入层来完成将输入向量压缩到低维稠密向量。